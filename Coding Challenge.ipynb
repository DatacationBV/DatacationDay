{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to the Datacation Bootcamp!\n",
    "\n",
    "Today, we present a coding challenge to you.\n",
    "In this challenge, you will be given two brain tumor dataset. A train and a test dataset.\n",
    "The target variable has been removed from the test dataset. You will try different Machine Learning models and\n",
    "use your best model to predict whether patients have a brain tumor or not.\n",
    "\n",
    "Try to get as far as possible in the following exercises, increasing in difficulty:\n",
    "\n",
    "1. Loading the training set train_brain.csv and split the training set in a training and validation set, then preprocess the data. Options include:\n",
    "    - imputing missing values\n",
    "    - one-hot-encoding categorical values\n",
    "    - scaling the data\n",
    "2. Implement the machine learning model called the Support Vector Machine (SVM) and optimize based on the validation accuracy.\n",
    "3. Visualize the SVM accuracy results in a graph.\n",
    "4. Use a grid search to find the optimal hyperparameters of the SVM, KNN and RandomForest models using 3-fold cross validation.\n",
    "5. Visualize the SVM, KNN and RandomForest accuracy results in a heatmap.\n",
    "6. Implement a Neural Network and visualize the loss and accuracy, both for the test and training dataset.\n",
    "7. Apply any type of model and preprocessing steps necessary to achieve the highest possible validation accuracy.\n",
    "8. Use the test_brain.csv dataset to predict whether the patients have a brain tumor or not. The target variable has been removed from the dataset.\n",
    "   Save the prediction results in a list with the same order as the patients in the test dataset.\n",
    "   Use the given code to store the list as .pkl file and save it using your group number.\n",
    "   Finally, do a push request to the github repository. We will calculate your final accuracy score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20173845\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:669: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0        1        2        3        4        5        6        7    \\\n",
      "0  14.1154  26.9888  18.0004  37.9845  9.57692  7.73521  31.5357  9.71818   \n",
      "1  4.01769  19.3011  12.8761  34.1732  12.0313  7.44901  30.5093  3.91994   \n",
      "2  6.03816  28.2465  15.4586  32.3316  9.08333  9.26768  33.6227  9.55485   \n",
      "3  12.3054  23.0694  14.1018  25.7072  5.84181  11.6547  36.1815   5.8799   \n",
      "4  6.03819  28.0759  15.6182  32.7191  9.05655  9.26738  33.6227  2.93995   \n",
      "\n",
      "       8        9    ... 91  92  93  94  95  96  97  98  99  100  \n",
      "0  25.4178  16.3847  ...   C   F   B   D   B   F   A   B   F   K  \n",
      "1  23.1735  18.7209  ...   A   F   B   D   C   G   C   A   A   V  \n",
      "2  24.0309   14.165  ...   A   B   B   B   C   G   C   A   A   A  \n",
      "3  25.4109  12.2382  ...   A   B   B   B   C   F   A   A   O   R  \n",
      "4  23.6222  14.1649  ...   A   F   B   D   B   C   D   B   E  AC  \n",
      "\n",
      "[5 rows x 101 columns]\n"
     ]
    }
   ],
   "source": [
    "######################################   EXERCISE 1   ######################################\n",
    "'''\n",
    "Loading the training set train_brain.csv and split the training set in a training and validation set, then preprocess the data. Options include:\n",
    "    - imputing missing values\n",
    "    - one-hot-encoding categorical values\n",
    "    - scaling the data\n",
    "'''\n",
    "\n",
    "# Read in the dataset: (https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('train_brain.csv')\n",
    "X = data.drop(columns=['target'])\n",
    "Y = data['target']\n",
    "\n",
    "\n",
    "\n",
    "# Split the training set in a train and validation set, use random_state = 0: (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=0)\n",
    "# Impute missing values: (https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import numpy as np\n",
    "#Numerical data\n",
    "X_train_numerical = X_train.select_dtypes(include=np.number)\n",
    "num_columns = X_train_numerical.columns\n",
    "imp = IterativeImputer(max_iter=5, random_state=0)\n",
    "X_train_numerical = pd.DataFrame(imp.fit_transform(X_train_numerical))\n",
    "X_train_numerical.columns = num_columns\n",
    "\n",
    "#Categorical data\n",
    "X_train_cat = X_train.select_dtypes(exclude=np.number)\n",
    "\n",
    "#Combine again\n",
    "X_train_numerical.set_index(X_train_cat.index, inplace=True)\n",
    "X_train = pd.concat([X_train_numerical, X_train_cat], axis=1)\n",
    "\n",
    "#Impute categorical data\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_most = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "X_train = pd.DataFrame(imp_most.fit_transform(X_train))\n",
    "\n",
    "# Scale numerical columns: (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 2   ######################################\n",
    "'''\n",
    "Implement the machine learning model called the Support Vector Machine (SVM) and optimize based on the validation accuracy.\n",
    "'''\n",
    "\n",
    "# Implement the Support Vector Machine: (https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 3   ######################################\n",
    "'''\n",
    "Visualize the SVM accuracy results in a graph.\n",
    "'''\n",
    "\n",
    "# Visualize the SVM results: (https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 4   ######################################\n",
    "'''\n",
    "Use a grid search to find the optimal hyperparameters of the SVM, KNN and RandomForest models using 3-fold cross validation.\n",
    "'''\n",
    "\n",
    "# Make use of GridSearchCV: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# KNN: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "# RandomForest: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 5   ######################################\n",
    "'''\n",
    "Visualize the SVM, KNN and RandomForest accuracy results in a heatmap.\n",
    "'''\n",
    "\n",
    "# Make us of a heatmap: https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 6   ######################################\n",
    "'''\n",
    "Implement a basic Neural Network and visualize the loss and accuracy, both for the test and training dataset.\n",
    "'''\n",
    "\n",
    "# Make use of the MLPClassifier: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 7   ######################################\n",
    "'''\n",
    "Apply any type of model and preprocessing steps necessary to achieve the highest possible validation accuracy.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 8   ######################################\n",
    "'''\n",
    "Time to predict using your best ML model!\n",
    "Use the test_brain.csv dataset to predict whether the patients have a brain tumor or not. The target variable has been removed from the dataset.\n",
    "Save the prediction results in a list with the same order as the patients in the test dataset.\n",
    "Use the below given code to store the list as .pkl file and save it using your group number.\n",
    "Finally, do a push request to the github repository. We will calculate your final accuracy score.\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "group_number = 0\n",
    "ypred = []\n",
    "\n",
    "with open(f'test_predictions_group_{group_number}.pkl', 'wb') as f:\n",
    "    pickle.dump(ypred, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
