{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to the Datacation Bootcamp!\n",
    "\n",
    "Today, we present a coding challenge to you.\n",
    "In this challenge, you will be given two brain tumor dataset. A train and a test dataset.\n",
    "The target variable has been removed from the test dataset. You will try different Machine Learning models and\n",
    "use your best model to predict whether patients have a brain tumor or not.\n",
    "\n",
    "Try to get as far as possible in the following exercises, increasing in difficulty:\n",
    "\n",
    "1. Loading the training set train_brain.csv and split the training set in a training and validation set, then preprocess the data. Options include:\n",
    "    - imputing missing values\n",
    "    - one-hot-encoding categorical values\n",
    "    - scaling the data\n",
    "2. Implement the machine learning model called the Support Vector Machine (SVM) and optimize based on the validation accuracy.\n",
    "3. Visualize the SVM accuracy results in a graph.\n",
    "4. Use a grid search to find the optimal hyperparameters of the SVM, KNN and RandomForest models using 3-fold cross validation.\n",
    "5. Visualize the SVM, KNN and RandomForest accuracy results in a heatmap.\n",
    "6. Implement a Neural Network and visualize the loss and accuracy, both for the test and training dataset.\n",
    "7. Apply any type of model and preprocessing steps necessary to achieve the highest possible validation accuracy.\n",
    "8. Use the test_brain.csv dataset to predict whether the patients have a brain tumor or not. The target variable has been removed from the dataset.\n",
    "   Save the prediction results in a list with the same order as the patients in the test dataset.\n",
    "   Use the given code to store the list as .pkl file and save it using your group number.\n",
    "   Finally, do a push request to the github repository. We will calculate your final accuracy score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 1   ######################################\n",
    "'''\n",
    "Loading the training set train_brain.csv and split the training set in a training and validation set, then preprocess the data. Options include:\n",
    "    - imputing missing values\n",
    "    - one-hot-encoding categorical values\n",
    "    - scaling the data\n",
    "'''\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Read in the dataset: (https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n",
    "train = pd.read_csv(\"train_brain.csv\")\n",
    "test = pd.read_csv(\"test_brain.csv\")\n",
    "# Split the training set in a train and validation set, use random_state = 0: (https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "train_split,validation = train_test_split(train, test_size=0.3, random_state=0)\n",
    "\n",
    "# Impute missing values: (https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n",
    "imp_mean = SimpleImputer(missing_values=np.nan,strategy='most_frequent')\n",
    "imp_mean.fit(train_split)\n",
    "train_imputed = imp_mean.transform(train_split)\n",
    "\n",
    "imp_mean.fit(validation)\n",
    "vali_imputed = imp_mean.transform(validation)\n",
    "\n",
    "# Scale numerical columns: (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "transpose_1 = train_imputed.transpose()\n",
    "transpose_2 = vali_imputed.transpose()\n",
    "transpose = transpose_1\n",
    "\n",
    "for i,column in enumerate(transpose):\n",
    "    if not isinstance(column[0], str):\n",
    "        array = column.reshape(-1, 1)\n",
    "        scaler.fit(array)\n",
    "        array= scaler.transform(array)\n",
    "        transpose[i] = array.reshape(-1)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "train_scaled = transpose.transpose()\n",
    "#vali_scaled = transpose.transpose()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "imp_mean.fit(test)\n",
    "test_imputed = imp_mean.transform(test)\n",
    "transpose = test_imputed.transpose()\n",
    "\n",
    "for i,column in enumerate(transpose):\n",
    "    if not isinstance(column[0], str):\n",
    "        array = column.reshape(-1, 1)\n",
    "        scaler.fit(array)\n",
    "        array= scaler.transform(array)\n",
    "        transpose[i] = array.reshape(-1)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "test_scaled = transpose.transpose()\n",
    "\n",
    "# Impute missing values: (https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n",
    "cols = test.columns\n",
    "datatypes = test.dtypes\n",
    "\n",
    "test_df = pd.DataFrame(test_scaled, columns=cols)\n",
    "\n",
    "# First cast all columns that are not 'object's to numeric columns,\n",
    "#   then normalize all numeric columns (manually implemented)\n",
    "for i in range(len(cols)):\n",
    "    if datatypes[i] != 'O':\n",
    "        test_df[cols[i]] = test_df[cols[i]].astype(datatypes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_1 = train_imputed.transpose()\n",
    "transpose_2 = vali_imputed.transpose()\n",
    "transpose = transpose_2\n",
    "\n",
    "for i,column in enumerate(transpose):\n",
    "    if not isinstance(column[0], str):\n",
    "        array = column.reshape(-1, 1)\n",
    "        scaler.fit(array)\n",
    "        array= scaler.transform(array)\n",
    "        transpose[i] = array.reshape(-1)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "#train_scaled = transpose.transpose()\n",
    "vali_scaled = transpose.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values: (https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n",
    "cols = train.columns\n",
    "datatypes = train.dtypes\n",
    "\n",
    "train_df = pd.DataFrame(train_scaled, columns=cols)\n",
    "vali_df =pd.DataFrame(vali_scaled, columns=cols)\n",
    "\n",
    "# First cast all columns that are not 'object's to numeric columns,\n",
    "#   then normalize all numeric columns (manually implemented)\n",
    "for i in range(len(cols)):\n",
    "    if datatypes[i] != 'O':\n",
    "        train_df[cols[i]] = train_df[cols[i]].astype(datatypes[i])\n",
    "        vali_df[cols[i]] = vali_df[cols[i]].astype(datatypes[i])\n",
    "        #train_df[cols[i]] = (train_df[cols[i]] - train_df[cols[i]].mean()) / train_df[cols[i]].std()\n",
    "\n",
    "X_train = train_df.drop('19', axis=1)\n",
    "y_train = train_df['19']\n",
    "X_vali = vali_df.drop('19', axis=1)\n",
    "y_vali = vali_df['19']\n",
    "        \n",
    "# Encode categorical columns to one-hot encoding style\n",
    "train_onehot = pd.get_dummies(train_df)\n",
    "vali_onehot = pd.get_dummies(vali_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values: (https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html)\n",
    "cols = train.columns\n",
    "datatypes = train.dtypes\n",
    "\n",
    "train_df = pd.DataFrame(train_scaled, columns=cols)\n",
    "vali_df =pd.DataFrame(vali_scaled, columns=cols)\n",
    "\n",
    "# First cast all columns that are not 'object's to numeric columns,\n",
    "#   then normalize all numeric columns (manually implemented)\n",
    "for i in range(len(cols)):\n",
    "    if datatypes[i] != 'O':\n",
    "        train_df[cols[i]] = train_df[cols[i]].astype(datatypes[i])\n",
    "        vali_df[cols[i]] = vali_df[cols[i]].astype(datatypes[i])\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = train_df.select_dtypes(['number'])\n",
    "valid_num = vali_df.select_dtypes(['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_num = test_df.select_dtypes(['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.455487</td>\n",
       "      <td>1.530271</td>\n",
       "      <td>C</td>\n",
       "      <td>0.533798</td>\n",
       "      <td>2.699543</td>\n",
       "      <td>-0.683785</td>\n",
       "      <td>-0.304898</td>\n",
       "      <td>-0.041805</td>\n",
       "      <td>0.182059</td>\n",
       "      <td>0.711944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.685880</td>\n",
       "      <td>-1.670945</td>\n",
       "      <td>-0.126435</td>\n",
       "      <td>V</td>\n",
       "      <td>0.787338</td>\n",
       "      <td>-1.334376</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.156410</td>\n",
       "      <td>0.050476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.800250</td>\n",
       "      <td>-0.657228</td>\n",
       "      <td>C</td>\n",
       "      <td>0.328634</td>\n",
       "      <td>-0.935224</td>\n",
       "      <td>0.584068</td>\n",
       "      <td>-0.366351</td>\n",
       "      <td>-0.725802</td>\n",
       "      <td>2.904398</td>\n",
       "      <td>3.315278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>-0.008565</td>\n",
       "      <td>0.375755</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.047877</td>\n",
       "      <td>0.444585</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.078818</td>\n",
       "      <td>-0.796004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.800250</td>\n",
       "      <td>-0.657228</td>\n",
       "      <td>C</td>\n",
       "      <td>0.328634</td>\n",
       "      <td>-0.935224</td>\n",
       "      <td>0.584068</td>\n",
       "      <td>-0.366351</td>\n",
       "      <td>-0.725802</td>\n",
       "      <td>3.360744</td>\n",
       "      <td>3.988174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>-0.008565</td>\n",
       "      <td>0.375755</td>\n",
       "      <td>BY</td>\n",
       "      <td>-1.047877</td>\n",
       "      <td>0.444585</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.078818</td>\n",
       "      <td>-0.796004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.563330</td>\n",
       "      <td>1.118313</td>\n",
       "      <td>C</td>\n",
       "      <td>0.544665</td>\n",
       "      <td>0.212928</td>\n",
       "      <td>-1.873994</td>\n",
       "      <td>1.553644</td>\n",
       "      <td>0.133174</td>\n",
       "      <td>-0.400175</td>\n",
       "      <td>-0.115421</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.781179</td>\n",
       "      <td>0.794111</td>\n",
       "      <td>0.692014</td>\n",
       "      <td>AT</td>\n",
       "      <td>0.388435</td>\n",
       "      <td>-0.940897</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.442542</td>\n",
       "      <td>0.441158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.602630</td>\n",
       "      <td>0.790340</td>\n",
       "      <td>C</td>\n",
       "      <td>2.352711</td>\n",
       "      <td>1.067671</td>\n",
       "      <td>1.078103</td>\n",
       "      <td>0.801526</td>\n",
       "      <td>-0.755667</td>\n",
       "      <td>-0.038245</td>\n",
       "      <td>-0.474978</td>\n",
       "      <td>...</td>\n",
       "      <td>1.515184</td>\n",
       "      <td>-1.212162</td>\n",
       "      <td>-0.824331</td>\n",
       "      <td>AG</td>\n",
       "      <td>0.465018</td>\n",
       "      <td>5.574691</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.285495</td>\n",
       "      <td>2.570225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14516</th>\n",
       "      <td>-0.800250</td>\n",
       "      <td>-0.657228</td>\n",
       "      <td>C</td>\n",
       "      <td>0.328634</td>\n",
       "      <td>-0.935224</td>\n",
       "      <td>0.584068</td>\n",
       "      <td>-0.366351</td>\n",
       "      <td>-0.725802</td>\n",
       "      <td>1.488153</td>\n",
       "      <td>1.284469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>-0.008565</td>\n",
       "      <td>0.375755</td>\n",
       "      <td>BJ</td>\n",
       "      <td>-1.047877</td>\n",
       "      <td>0.444585</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.078818</td>\n",
       "      <td>-0.796004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14517</th>\n",
       "      <td>-0.800250</td>\n",
       "      <td>-0.657228</td>\n",
       "      <td>C</td>\n",
       "      <td>0.328634</td>\n",
       "      <td>-0.935224</td>\n",
       "      <td>0.584068</td>\n",
       "      <td>-0.366351</td>\n",
       "      <td>-0.725802</td>\n",
       "      <td>0.166324</td>\n",
       "      <td>0.204182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>-0.008565</td>\n",
       "      <td>0.375755</td>\n",
       "      <td>CG</td>\n",
       "      <td>-1.047877</td>\n",
       "      <td>0.444585</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.078818</td>\n",
       "      <td>-0.796004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14518</th>\n",
       "      <td>-0.439200</td>\n",
       "      <td>-0.814075</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.092275</td>\n",
       "      <td>0.441402</td>\n",
       "      <td>0.179724</td>\n",
       "      <td>-0.008464</td>\n",
       "      <td>-0.012484</td>\n",
       "      <td>-0.431646</td>\n",
       "      <td>-0.369674</td>\n",
       "      <td>...</td>\n",
       "      <td>1.387317</td>\n",
       "      <td>-0.002608</td>\n",
       "      <td>-0.353152</td>\n",
       "      <td>BC</td>\n",
       "      <td>2.340939</td>\n",
       "      <td>0.291083</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.186038</td>\n",
       "      <td>-0.430478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14519</th>\n",
       "      <td>0.279904</td>\n",
       "      <td>1.330578</td>\n",
       "      <td>C</td>\n",
       "      <td>1.776671</td>\n",
       "      <td>0.254458</td>\n",
       "      <td>0.204819</td>\n",
       "      <td>1.324487</td>\n",
       "      <td>-0.112409</td>\n",
       "      <td>0.921655</td>\n",
       "      <td>0.740127</td>\n",
       "      <td>...</td>\n",
       "      <td>2.166647</td>\n",
       "      <td>0.193639</td>\n",
       "      <td>-1.021590</td>\n",
       "      <td>BL</td>\n",
       "      <td>0.859242</td>\n",
       "      <td>0.731156</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.464892</td>\n",
       "      <td>0.234964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14520</th>\n",
       "      <td>-0.079984</td>\n",
       "      <td>1.373703</td>\n",
       "      <td>C</td>\n",
       "      <td>1.332394</td>\n",
       "      <td>0.944897</td>\n",
       "      <td>-1.327015</td>\n",
       "      <td>1.151782</td>\n",
       "      <td>-0.464162</td>\n",
       "      <td>-0.589008</td>\n",
       "      <td>-0.269747</td>\n",
       "      <td>...</td>\n",
       "      <td>1.155538</td>\n",
       "      <td>-1.072579</td>\n",
       "      <td>-1.928413</td>\n",
       "      <td>AY</td>\n",
       "      <td>0.632067</td>\n",
       "      <td>-1.543152</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.767772</td>\n",
       "      <td>0.097503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14521 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2  3         4         5         6         7  \\\n",
       "0     -0.455487  1.530271  C  0.533798  2.699543 -0.683785 -0.304898   \n",
       "1     -0.800250 -0.657228  C  0.328634 -0.935224  0.584068 -0.366351   \n",
       "2     -0.800250 -0.657228  C  0.328634 -0.935224  0.584068 -0.366351   \n",
       "3      0.563330  1.118313  C  0.544665  0.212928 -1.873994  1.553644   \n",
       "4      0.602630  0.790340  C  2.352711  1.067671  1.078103  0.801526   \n",
       "...         ...       ... ..       ...       ...       ...       ...   \n",
       "14516 -0.800250 -0.657228  C  0.328634 -0.935224  0.584068 -0.366351   \n",
       "14517 -0.800250 -0.657228  C  0.328634 -0.935224  0.584068 -0.366351   \n",
       "14518 -0.439200 -0.814075  C -0.092275  0.441402  0.179724 -0.008464   \n",
       "14519  0.279904  1.330578  C  1.776671  0.254458  0.204819  1.324487   \n",
       "14520 -0.079984  1.373703  C  1.332394  0.944897 -1.327015  1.151782   \n",
       "\n",
       "              8         9        10  ...        93        94        95  96  \\\n",
       "0     -0.041805  0.182059  0.711944  ... -0.685880 -1.670945 -0.126435   V   \n",
       "1     -0.725802  2.904398  3.315278  ...  0.000816 -0.008565  0.375755   A   \n",
       "2     -0.725802  3.360744  3.988174  ...  0.000816 -0.008565  0.375755  BY   \n",
       "3      0.133174 -0.400175 -0.115421  ... -1.781179  0.794111  0.692014  AT   \n",
       "4     -0.755667 -0.038245 -0.474978  ...  1.515184 -1.212162 -0.824331  AG   \n",
       "...         ...       ...       ...  ...       ...       ...       ...  ..   \n",
       "14516 -0.725802  1.488153  1.284469  ...  0.000816 -0.008565  0.375755  BJ   \n",
       "14517 -0.725802  0.166324  0.204182  ...  0.000816 -0.008565  0.375755  CG   \n",
       "14518 -0.012484 -0.431646 -0.369674  ...  1.387317 -0.002608 -0.353152  BC   \n",
       "14519 -0.112409  0.921655  0.740127  ...  2.166647  0.193639 -1.021590  BL   \n",
       "14520 -0.464162 -0.589008 -0.269747  ...  1.155538 -1.072579 -1.928413  AY   \n",
       "\n",
       "             97        98  99       100       101  target  \n",
       "0      0.787338 -1.334376   1 -1.156410  0.050476       0  \n",
       "1     -1.047877  0.444585   1 -0.078818 -0.796004       1  \n",
       "2     -1.047877  0.444585   1 -0.078818 -0.796004       0  \n",
       "3      0.388435 -0.940897   0 -0.442542  0.441158       0  \n",
       "4      0.465018  5.574691   3 -1.285495  2.570225       0  \n",
       "...         ...       ...  ..       ...       ...     ...  \n",
       "14516 -1.047877  0.444585   0 -0.078818 -0.796004       0  \n",
       "14517 -1.047877  0.444585   0 -0.078818 -0.796004       0  \n",
       "14518  2.340939  0.291083   0 -0.186038 -0.430478       0  \n",
       "14519  0.859242  0.731156   0 -0.464892  0.234964       0  \n",
       "14520  0.632067 -1.543152   0 -0.767772  0.097503       0  \n",
       "\n",
       "[14521 rows x 102 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vali_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.804027</td>\n",
       "      <td>-0.708418</td>\n",
       "      <td>-0.641359</td>\n",
       "      <td>0.713120</td>\n",
       "      <td>-0.656371</td>\n",
       "      <td>-0.779224</td>\n",
       "      <td>-0.046616</td>\n",
       "      <td>0.495877</td>\n",
       "      <td>-0.509877</td>\n",
       "      <td>-0.520637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930517</td>\n",
       "      <td>-0.344857</td>\n",
       "      <td>-0.314412</td>\n",
       "      <td>-0.058565</td>\n",
       "      <td>0.382354</td>\n",
       "      <td>-0.131699</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.494324</td>\n",
       "      <td>-0.811185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.804027</td>\n",
       "      <td>-0.708418</td>\n",
       "      <td>-0.641359</td>\n",
       "      <td>0.713120</td>\n",
       "      <td>-0.656371</td>\n",
       "      <td>-0.779224</td>\n",
       "      <td>-0.046616</td>\n",
       "      <td>-0.416755</td>\n",
       "      <td>-0.883957</td>\n",
       "      <td>-0.520637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387587</td>\n",
       "      <td>-0.344857</td>\n",
       "      <td>-0.314412</td>\n",
       "      <td>-0.058565</td>\n",
       "      <td>0.382354</td>\n",
       "      <td>-0.131699</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.494324</td>\n",
       "      <td>-0.811185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.392942</td>\n",
       "      <td>-1.548836</td>\n",
       "      <td>-2.360166</td>\n",
       "      <td>-0.686210</td>\n",
       "      <td>-0.512330</td>\n",
       "      <td>-1.378592</td>\n",
       "      <td>-0.827800</td>\n",
       "      <td>1.021800</td>\n",
       "      <td>-0.491925</td>\n",
       "      <td>1.485551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426909</td>\n",
       "      <td>-1.970369</td>\n",
       "      <td>5.592551</td>\n",
       "      <td>-1.958071</td>\n",
       "      <td>-0.012836</td>\n",
       "      <td>-1.695431</td>\n",
       "      <td>0</td>\n",
       "      <td>7.379186</td>\n",
       "      <td>0.279437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.804027</td>\n",
       "      <td>-0.708418</td>\n",
       "      <td>-0.641359</td>\n",
       "      <td>0.713120</td>\n",
       "      <td>-0.656371</td>\n",
       "      <td>-0.779224</td>\n",
       "      <td>-0.046616</td>\n",
       "      <td>1.238357</td>\n",
       "      <td>0.842654</td>\n",
       "      <td>-0.520637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401070</td>\n",
       "      <td>-0.344857</td>\n",
       "      <td>-0.314412</td>\n",
       "      <td>-0.058565</td>\n",
       "      <td>0.382354</td>\n",
       "      <td>-0.131699</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.494324</td>\n",
       "      <td>-0.811185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.341709</td>\n",
       "      <td>-1.062458</td>\n",
       "      <td>-1.689021</td>\n",
       "      <td>-0.655218</td>\n",
       "      <td>1.054341</td>\n",
       "      <td>-1.728540</td>\n",
       "      <td>0.316132</td>\n",
       "      <td>3.295645</td>\n",
       "      <td>2.635402</td>\n",
       "      <td>4.165475</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.852143</td>\n",
       "      <td>-2.046016</td>\n",
       "      <td>0.376581</td>\n",
       "      <td>1.136826</td>\n",
       "      <td>-0.820327</td>\n",
       "      <td>-2.166242</td>\n",
       "      <td>2</td>\n",
       "      <td>3.125428</td>\n",
       "      <td>0.091711</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33876</th>\n",
       "      <td>0.834978</td>\n",
       "      <td>0.354109</td>\n",
       "      <td>0.735307</td>\n",
       "      <td>0.587800</td>\n",
       "      <td>0.183637</td>\n",
       "      <td>-1.526542</td>\n",
       "      <td>0.373999</td>\n",
       "      <td>-0.602375</td>\n",
       "      <td>-0.633870</td>\n",
       "      <td>0.408800</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.118199</td>\n",
       "      <td>-1.946360</td>\n",
       "      <td>-1.148921</td>\n",
       "      <td>1.002518</td>\n",
       "      <td>-2.312056</td>\n",
       "      <td>-1.273795</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714005</td>\n",
       "      <td>1.646079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33877</th>\n",
       "      <td>0.382469</td>\n",
       "      <td>1.841819</td>\n",
       "      <td>0.108445</td>\n",
       "      <td>-0.198922</td>\n",
       "      <td>0.470824</td>\n",
       "      <td>-0.340837</td>\n",
       "      <td>0.444170</td>\n",
       "      <td>-0.416755</td>\n",
       "      <td>-0.201483</td>\n",
       "      <td>0.681515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>-1.178840</td>\n",
       "      <td>-0.522095</td>\n",
       "      <td>0.338015</td>\n",
       "      <td>-0.824094</td>\n",
       "      <td>-0.572929</td>\n",
       "      <td>0</td>\n",
       "      <td>0.432639</td>\n",
       "      <td>0.469628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33878</th>\n",
       "      <td>-0.804027</td>\n",
       "      <td>-0.708418</td>\n",
       "      <td>-0.641359</td>\n",
       "      <td>0.713120</td>\n",
       "      <td>-0.656371</td>\n",
       "      <td>-0.779224</td>\n",
       "      <td>-0.046616</td>\n",
       "      <td>-1.252044</td>\n",
       "      <td>-0.918103</td>\n",
       "      <td>-0.520637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111776</td>\n",
       "      <td>-0.344857</td>\n",
       "      <td>-0.314412</td>\n",
       "      <td>-0.058565</td>\n",
       "      <td>0.382354</td>\n",
       "      <td>-0.131699</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.494324</td>\n",
       "      <td>-0.811185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33879</th>\n",
       "      <td>0.586232</td>\n",
       "      <td>-0.912161</td>\n",
       "      <td>-0.507078</td>\n",
       "      <td>0.133900</td>\n",
       "      <td>0.701337</td>\n",
       "      <td>1.185910</td>\n",
       "      <td>-0.265716</td>\n",
       "      <td>1.423977</td>\n",
       "      <td>1.830150</td>\n",
       "      <td>-0.259416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138019</td>\n",
       "      <td>0.157905</td>\n",
       "      <td>-0.019627</td>\n",
       "      <td>-0.086892</td>\n",
       "      <td>0.769676</td>\n",
       "      <td>0.879728</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.297428</td>\n",
       "      <td>0.847469</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33880</th>\n",
       "      <td>-0.804027</td>\n",
       "      <td>-0.708418</td>\n",
       "      <td>-0.641359</td>\n",
       "      <td>0.713120</td>\n",
       "      <td>-0.656371</td>\n",
       "      <td>-0.779224</td>\n",
       "      <td>-0.046616</td>\n",
       "      <td>0.495877</td>\n",
       "      <td>-0.712761</td>\n",
       "      <td>-0.520637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872457</td>\n",
       "      <td>-0.344857</td>\n",
       "      <td>-0.314412</td>\n",
       "      <td>-0.058565</td>\n",
       "      <td>0.382354</td>\n",
       "      <td>-0.131699</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.494324</td>\n",
       "      <td>-0.811185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33881 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2         4         5         6         7         8  \\\n",
       "0     -0.804027 -0.708418 -0.641359  0.713120 -0.656371 -0.779224 -0.046616   \n",
       "1     -0.804027 -0.708418 -0.641359  0.713120 -0.656371 -0.779224 -0.046616   \n",
       "2      2.392942 -1.548836 -2.360166 -0.686210 -0.512330 -1.378592 -0.827800   \n",
       "3     -0.804027 -0.708418 -0.641359  0.713120 -0.656371 -0.779224 -0.046616   \n",
       "4      0.341709 -1.062458 -1.689021 -0.655218  1.054341 -1.728540  0.316132   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "33876  0.834978  0.354109  0.735307  0.587800  0.183637 -1.526542  0.373999   \n",
       "33877  0.382469  1.841819  0.108445 -0.198922  0.470824 -0.340837  0.444170   \n",
       "33878 -0.804027 -0.708418 -0.641359  0.713120 -0.656371 -0.779224 -0.046616   \n",
       "33879  0.586232 -0.912161 -0.507078  0.133900  0.701337  1.185910 -0.265716   \n",
       "33880 -0.804027 -0.708418 -0.641359  0.713120 -0.656371 -0.779224 -0.046616   \n",
       "\n",
       "              9        10        11  ...        92        93        94  \\\n",
       "0      0.495877 -0.509877 -0.520637  ...  0.930517 -0.344857 -0.314412   \n",
       "1     -0.416755 -0.883957 -0.520637  ...  0.387587 -0.344857 -0.314412   \n",
       "2      1.021800 -0.491925  1.485551  ...  0.426909 -1.970369  5.592551   \n",
       "3      1.238357  0.842654 -0.520637  ...  0.401070 -0.344857 -0.314412   \n",
       "4      3.295645  2.635402  4.165475  ... -1.852143 -2.046016  0.376581   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "33876 -0.602375 -0.633870  0.408800  ... -2.118199 -1.946360 -1.148921   \n",
       "33877 -0.416755 -0.201483  0.681515  ... -0.113212 -1.178840 -0.522095   \n",
       "33878 -1.252044 -0.918103 -0.520637  ...  0.111776 -0.344857 -0.314412   \n",
       "33879  1.423977  1.830150 -0.259416  ... -0.138019  0.157905 -0.019627   \n",
       "33880  0.495877 -0.712761 -0.520637  ...  0.872457 -0.344857 -0.314412   \n",
       "\n",
       "             95        97        98  99       100       101  target  \n",
       "0     -0.058565  0.382354 -0.131699   0 -0.494324 -0.811185       0  \n",
       "1     -0.058565  0.382354 -0.131699   0 -0.494324 -0.811185       0  \n",
       "2     -1.958071 -0.012836 -1.695431   0  7.379186  0.279437       0  \n",
       "3     -0.058565  0.382354 -0.131699   2 -0.494324 -0.811185       0  \n",
       "4      1.136826 -0.820327 -2.166242   2  3.125428  0.091711       0  \n",
       "...         ...       ...       ...  ..       ...       ...     ...  \n",
       "33876  1.002518 -2.312056 -1.273795   0  0.714005  1.646079       0  \n",
       "33877  0.338015 -0.824094 -0.572929   0  0.432639  0.469628       0  \n",
       "33878 -0.058565  0.382354 -0.131699   0 -0.494324 -0.811185       1  \n",
       "33879 -0.086892  0.769676  0.879728   2 -0.297428  0.847469       0  \n",
       "33880 -0.058565  0.382354 -0.131699   0 -0.494324 -0.811185       0  \n",
       "\n",
       "[33881 rows x 85 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.455487</td>\n",
       "      <td>1.530271</td>\n",
       "      <td>0.533798</td>\n",
       "      <td>2.699543</td>\n",
       "      <td>-0.683785</td>\n",
       "      <td>-0.304898</td>\n",
       "      <td>-0.041805</td>\n",
       "      <td>0.182059</td>\n",
       "      <td>0.711944</td>\n",
       "      <td>-0.108279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475998</td>\n",
       "      <td>-0.685880</td>\n",
       "      <td>-1.670945</td>\n",
       "      <td>-0.126435</td>\n",
       "      <td>0.787338</td>\n",
       "      <td>-1.334376</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.156410</td>\n",
       "      <td>0.050476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.800250</td>\n",
       "      <td>-0.657228</td>\n",
       "      <td>0.328634</td>\n",
       "      <td>-0.935224</td>\n",
       "      <td>0.584068</td>\n",
       "      <td>-0.366351</td>\n",
       "      <td>-0.725802</td>\n",
       "      <td>2.904398</td>\n",
       "      <td>3.315278</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.209240</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>-0.008565</td>\n",
       "      <td>0.375755</td>\n",
       "      <td>-1.047877</td>\n",
       "      <td>0.444585</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.078818</td>\n",
       "      <td>-0.796004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.800250</td>\n",
       "      <td>-0.657228</td>\n",
       "      <td>0.328634</td>\n",
       "      <td>-0.935224</td>\n",
       "      <td>0.584068</td>\n",
       "      <td>-0.366351</td>\n",
       "      <td>-0.725802</td>\n",
       "      <td>3.360744</td>\n",
       "      <td>3.988174</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.349203</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>-0.008565</td>\n",
       "      <td>0.375755</td>\n",
       "      <td>-1.047877</td>\n",
       "      <td>0.444585</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.078818</td>\n",
       "      <td>-0.796004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.563330</td>\n",
       "      <td>1.118313</td>\n",
       "      <td>0.544665</td>\n",
       "      <td>0.212928</td>\n",
       "      <td>-1.873994</td>\n",
       "      <td>1.553644</td>\n",
       "      <td>0.133174</td>\n",
       "      <td>-0.400175</td>\n",
       "      <td>-0.115421</td>\n",
       "      <td>0.150986</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.628246</td>\n",
       "      <td>-1.781179</td>\n",
       "      <td>0.794111</td>\n",
       "      <td>0.692014</td>\n",
       "      <td>0.388435</td>\n",
       "      <td>-0.940897</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.442542</td>\n",
       "      <td>0.441158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.602630</td>\n",
       "      <td>0.790340</td>\n",
       "      <td>2.352711</td>\n",
       "      <td>1.067671</td>\n",
       "      <td>1.078103</td>\n",
       "      <td>0.801526</td>\n",
       "      <td>-0.755667</td>\n",
       "      <td>-0.038245</td>\n",
       "      <td>-0.474978</td>\n",
       "      <td>-0.982041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.817777</td>\n",
       "      <td>1.515184</td>\n",
       "      <td>-1.212162</td>\n",
       "      <td>-0.824331</td>\n",
       "      <td>0.465018</td>\n",
       "      <td>5.574691</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.285495</td>\n",
       "      <td>2.570225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14516</th>\n",
       "      <td>-0.800250</td>\n",
       "      <td>-0.657228</td>\n",
       "      <td>0.328634</td>\n",
       "      <td>-0.935224</td>\n",
       "      <td>0.584068</td>\n",
       "      <td>-0.366351</td>\n",
       "      <td>-0.725802</td>\n",
       "      <td>1.488153</td>\n",
       "      <td>1.284469</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650074</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>-0.008565</td>\n",
       "      <td>0.375755</td>\n",
       "      <td>-1.047877</td>\n",
       "      <td>0.444585</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.078818</td>\n",
       "      <td>-0.796004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14517</th>\n",
       "      <td>-0.800250</td>\n",
       "      <td>-0.657228</td>\n",
       "      <td>0.328634</td>\n",
       "      <td>-0.935224</td>\n",
       "      <td>0.584068</td>\n",
       "      <td>-0.366351</td>\n",
       "      <td>-0.725802</td>\n",
       "      <td>0.166324</td>\n",
       "      <td>0.204182</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350312</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>-0.008565</td>\n",
       "      <td>0.375755</td>\n",
       "      <td>-1.047877</td>\n",
       "      <td>0.444585</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.078818</td>\n",
       "      <td>-0.796004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14518</th>\n",
       "      <td>-0.439200</td>\n",
       "      <td>-0.814075</td>\n",
       "      <td>-0.092275</td>\n",
       "      <td>0.441402</td>\n",
       "      <td>0.179724</td>\n",
       "      <td>-0.008464</td>\n",
       "      <td>-0.012484</td>\n",
       "      <td>-0.431646</td>\n",
       "      <td>-0.369674</td>\n",
       "      <td>3.795517</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.372814</td>\n",
       "      <td>1.387317</td>\n",
       "      <td>-0.002608</td>\n",
       "      <td>-0.353152</td>\n",
       "      <td>2.340939</td>\n",
       "      <td>0.291083</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.186038</td>\n",
       "      <td>-0.430478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14519</th>\n",
       "      <td>0.279904</td>\n",
       "      <td>1.330578</td>\n",
       "      <td>1.776671</td>\n",
       "      <td>0.254458</td>\n",
       "      <td>0.204819</td>\n",
       "      <td>1.324487</td>\n",
       "      <td>-0.112409</td>\n",
       "      <td>0.921655</td>\n",
       "      <td>0.740127</td>\n",
       "      <td>-0.476544</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542836</td>\n",
       "      <td>2.166647</td>\n",
       "      <td>0.193639</td>\n",
       "      <td>-1.021590</td>\n",
       "      <td>0.859242</td>\n",
       "      <td>0.731156</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.464892</td>\n",
       "      <td>0.234964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14520</th>\n",
       "      <td>-0.079984</td>\n",
       "      <td>1.373703</td>\n",
       "      <td>1.332394</td>\n",
       "      <td>0.944897</td>\n",
       "      <td>-1.327015</td>\n",
       "      <td>1.151782</td>\n",
       "      <td>-0.464162</td>\n",
       "      <td>-0.589008</td>\n",
       "      <td>-0.269747</td>\n",
       "      <td>-0.945698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.786227</td>\n",
       "      <td>1.155538</td>\n",
       "      <td>-1.072579</td>\n",
       "      <td>-1.928413</td>\n",
       "      <td>0.632067</td>\n",
       "      <td>-1.543152</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.767772</td>\n",
       "      <td>0.097503</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14521 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2         4         5         6         7         8  \\\n",
       "0     -0.455487  1.530271  0.533798  2.699543 -0.683785 -0.304898 -0.041805   \n",
       "1     -0.800250 -0.657228  0.328634 -0.935224  0.584068 -0.366351 -0.725802   \n",
       "2     -0.800250 -0.657228  0.328634 -0.935224  0.584068 -0.366351 -0.725802   \n",
       "3      0.563330  1.118313  0.544665  0.212928 -1.873994  1.553644  0.133174   \n",
       "4      0.602630  0.790340  2.352711  1.067671  1.078103  0.801526 -0.755667   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "14516 -0.800250 -0.657228  0.328634 -0.935224  0.584068 -0.366351 -0.725802   \n",
       "14517 -0.800250 -0.657228  0.328634 -0.935224  0.584068 -0.366351 -0.725802   \n",
       "14518 -0.439200 -0.814075 -0.092275  0.441402  0.179724 -0.008464 -0.012484   \n",
       "14519  0.279904  1.330578  1.776671  0.254458  0.204819  1.324487 -0.112409   \n",
       "14520 -0.079984  1.373703  1.332394  0.944897 -1.327015  1.151782 -0.464162   \n",
       "\n",
       "              9        10        11  ...        92        93        94  \\\n",
       "0      0.182059  0.711944 -0.108279  ...  0.475998 -0.685880 -1.670945   \n",
       "1      2.904398  3.315278  0.002214  ... -1.209240  0.000816 -0.008565   \n",
       "2      3.360744  3.988174  0.002214  ... -0.349203  0.000816 -0.008565   \n",
       "3     -0.400175 -0.115421  0.150986  ... -1.628246 -1.781179  0.794111   \n",
       "4     -0.038245 -0.474978 -0.982041  ...  0.817777  1.515184 -1.212162   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "14516  1.488153  1.284469  0.002214  ...  0.650074  0.000816 -0.008565   \n",
       "14517  0.166324  0.204182  0.002214  ...  0.350312  0.000816 -0.008565   \n",
       "14518 -0.431646 -0.369674  3.795517  ... -0.372814  1.387317 -0.002608   \n",
       "14519  0.921655  0.740127 -0.476544  ... -0.542836  2.166647  0.193639   \n",
       "14520 -0.589008 -0.269747 -0.945698  ...  0.786227  1.155538 -1.072579   \n",
       "\n",
       "             95        97        98  99       100       101  target  \n",
       "0     -0.126435  0.787338 -1.334376   1 -1.156410  0.050476       0  \n",
       "1      0.375755 -1.047877  0.444585   1 -0.078818 -0.796004       1  \n",
       "2      0.375755 -1.047877  0.444585   1 -0.078818 -0.796004       0  \n",
       "3      0.692014  0.388435 -0.940897   0 -0.442542  0.441158       0  \n",
       "4     -0.824331  0.465018  5.574691   3 -1.285495  2.570225       0  \n",
       "...         ...       ...       ...  ..       ...       ...     ...  \n",
       "14516  0.375755 -1.047877  0.444585   0 -0.078818 -0.796004       0  \n",
       "14517  0.375755 -1.047877  0.444585   0 -0.078818 -0.796004       0  \n",
       "14518 -0.353152  2.340939  0.291083   0 -0.186038 -0.430478       0  \n",
       "14519 -1.021590  0.859242  0.731156   0 -0.464892  0.234964       0  \n",
       "14520 -1.928413  0.632067 -1.543152   0 -0.767772  0.097503       0  \n",
       "\n",
       "[14521 rows x 85 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 2   ######################################\n",
    "'''\n",
    "Implement the machine learning model called the Support Vector Machine (SVM) and optimize based on the validation accuracy.\n",
    "'''\n",
    "\n",
    "# Implement the Support Vector Machine: (https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n",
    "X_train = train_num.drop('target', axis=1)\n",
    "y_train = train_num['target']\n",
    "X_vali = valid_num.drop('target', axis=1)\n",
    "y_vali = valid_num['target']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = X_train[:100]\n",
    "y_train_1 = y_train[:100]\n",
    "X_vali_1 = X_vali[:100]\n",
    "y_vali_1 = y_vali[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\envs\\Thesis\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svclassifier = LinearSVC()\n",
    "svclassifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(X_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(test_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7544934921837338"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_vali, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      object\n",
       "1      object\n",
       "2      object\n",
       "3      object\n",
       "4      object\n",
       "        ...  \n",
       "97     object\n",
       "98     object\n",
       "99     object\n",
       "100    object\n",
       "101    object\n",
       "Length: 102, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.get_dummies(train_df)\n",
    "vali_df = pd.get_dummies(vali_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = pd.get_dummies(train_scaled)\n",
    "\n",
    "transpose_1 = train_imputed.transpose()\n",
    "transpose_2 = vali_imputed.transpose()\n",
    "transpose = transpose_1\n",
    "\n",
    "for i,column in enumerate(transpose):\n",
    "    if not isinstance(column[0], str):\n",
    "        array = column.reshape(-1, 1)\n",
    "        scaler.fit(array)\n",
    "        array= scaler.transform(array)\n",
    "        transpose[i] = array.reshape(-1)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "train_scaled = transpose.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 3   ######################################\n",
    "'''\n",
    "Visualize the SVM accuracy results in a graph.\n",
    "'''\n",
    "\n",
    "# Visualize the SVM results: (https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 4   ######################################\n",
    "'''\n",
    "Use a grid search to find the optimal hyperparameters of the SVM, KNN and RandomForest models using 3-fold cross validation.\n",
    "'''\n",
    "\n",
    "# Make use of GridSearchCV: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# KNN: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "# RandomForest: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 5   ######################################\n",
    "'''\n",
    "Visualize the SVM, KNN and RandomForest accuracy results in a heatmap.\n",
    "'''\n",
    "\n",
    "# Make us of a heatmap: https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 6   ######################################\n",
    "'''\n",
    "Implement a basic Neural Network and visualize the loss and accuracy, both for the test and training dataset.\n",
    "'''\n",
    "\n",
    "# Make use of the MLPClassifier: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 7   ######################################\n",
    "'''\n",
    "Apply any type of model and preprocessing steps necessary to achieve the highest possible validation accuracy.\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################   EXERCISE 8   ######################################\n",
    "'''\n",
    "Time to predict using your best ML model!\n",
    "Use the test_brain.csv dataset to predict whether the patients have a brain tumor or not. The target variable has been removed from the dataset.\n",
    "Save the prediction results in a list with the same order as the patients in the test dataset.\n",
    "Use the below given code to store the list as .pkl file and save it using your group number.\n",
    "Finally, do a push request to the github repository. We will calculate your final accuracy score.\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "group_number = 3\n",
    "ypred = y_pred\n",
    "\n",
    "with open(f'test_predictions_group_{group_number}.pkl', 'wb') as f:\n",
    "    pickle.dump(ypred, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
